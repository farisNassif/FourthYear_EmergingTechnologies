{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <b>Emerging Technologies 2019</b> </center> <br>\n",
    "\n",
    "> Student: Faris Nassif, G00347032<br>\n",
    "> Lecturer: Dr Ian McLoughlin<br>\n",
    "> [Project Brief](https://github.com/ianmcloughlin/project-2019-emtech/blob/master/project.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://www.tensorflow.org/tutorials/keras/classification\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reoccuring variables\n",
    "CONST_IMAGE_WIDTH, CONST_IMAGE_HEIGHT = 28, 28\n",
    "CONST_IMAGE_CHANNELS = 1\n",
    "CONST_NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These class names don't do anything in the model\n",
    "# Their function is just for visual plotting\n",
    "class_names = ['0', '1', '2', '3', '4', '5',\n",
    "               '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "numbers_mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data that was imported above \n",
    "# train_images and train_labels are the training set (What the model uses to learn)\n",
    "# test_images and test_labels are what the model is tested against after it's learned\n",
    "(train_images, train_labels), (test_images, test_labels) = numbers_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the input that will be inserted into the neural network (28,28,1)\n",
    "input_shape = (CONST_IMAGE_WIDTH, CONST_IMAGE_HEIGHT, CONST_IMAGE_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows there are 60,000 images in the training set, with each image represented as 28 x 28 pixels\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows there are 10,000 images in the training set, with each image represented as 28 x 28 pixels\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The data must be preprocessed before training the network\n",
    "# Pixel values fall in the range of 0 to 255\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale these values to a range of 0 to 1 before feeding them to the neural network \n",
    "# Divide the values by 255\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-49dbed463cfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Verifying the data is in the correct format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Display the first 25 images from the training set and the previously defined class_name below it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Verifying the data is in the correct format\n",
    "# Display the first 25 images from the training set and the previously defined class_name below it\n",
    "plt.figure(figsize=(8,8)) \n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create the model \"\"\"\n",
    "\n",
    "# Model type that allows creation layer by layer\n",
    "model = keras.Sequential()\n",
    "\n",
    "# A 2d convolution layer allows spatial convolution over images\n",
    "# Creates a convolution kernel (small matrix) \n",
    "model.add(Conv2D(32, # 32 represents the amount of filters \n",
    "                kernel_size=(5, 5), # Kernel_size 2 integers specifying width and height of the convolution window (5x5)  \n",
    "                padding='same', # Zero padding\n",
    "                activation='relu', # Relu worked best with my model https://datascience.stackexchange.com/questions/18667/relu-vs-sigmoid-in-mnist-example\n",
    "                input_shape=input_shape)) # Passed in value is equal to (28, 28, 1), same value as that of images to pass into the model\n",
    "    \n",
    "# **Temp, may change this\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))      \n",
    "\n",
    "# This time add another convolution layer with slightly different paramaters \n",
    "model.add(Conv2D(64, \n",
    "                (3, 3), \n",
    "                activation='relu')) \n",
    "\n",
    "# Used for downsampling the image size. \n",
    "# Eg. in a (2,2) pool it splits a pixel image into 4 chucks and takes the 4 highest values from each chunk\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))               \n",
    "\n",
    "# Dropout causes my model to crash when loaded, no choice but to exclude it\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# Flattens the 2D arrays for fully connected layers\n",
    "model.add(Flatten())  \n",
    "\n",
    "# Apply a dense layer with a output of 128 (nodes)\n",
    "model.add(Dense(128, \n",
    "                activation='relu'))\n",
    "\n",
    "# Apply a dense layer with a output of 50 (nodes)\n",
    "model.add(Dense(50, \n",
    "                    activation='relu'))\n",
    "\n",
    "# Apply a final dense layer with a output of 10 \n",
    "# Softmax is applied to the final layer as it can be used to represent categorical data, outputing results ranging from 0 upto 1\n",
    "model.add(Dense(CONST_NUM_CLASSES, \n",
    "                activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the model has been created, it must be compiled before training\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, # Loss function -> Measures how accurate the model is during training\n",
    "            optimizer='adam', # Optimizer -> How the model is updated based on the data it sees and its loss function.\n",
    "            metrics=['accuracy']) # Metrics -> Used to monitor the training and testing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulating the train/test data from a 3d => 4d numpy arrays\n",
    "# Conv2d is expected to have 4 dimensions\n",
    "train_images = train_images.reshape(train_images.shape[0], CONST_IMAGE_WIDTH, CONST_IMAGE_HEIGHT, CONST_IMAGE_CHANNELS)\n",
    "test_images = test_images.reshape(test_images.shape[0], CONST_IMAGE_WIDTH, CONST_IMAGE_HEIGHT, CONST_IMAGE_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring values are floats so decimal points can be used after division\n",
    "# https://stackoverflow.com/questions/48219442/use-tf-to-float-or-tf-image-convert-image-dtype-in-image-pipeline-for-cn\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a class vector (integers) to binary class matrix\n",
    "# https://keras.io/utils/\n",
    "train_labels = keras.utils.to_categorical(train_labels, CONST_NUM_CLASSES)\n",
    "test_labels = keras.utils.to_categorical(test_labels, CONST_NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 54s 901us/step - loss: 0.1228 - accuracy: 0.9617 - val_loss: 0.0502 - val_accuracy: 0.9829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x237cea510f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model. Training it requires..\n",
    "# 1) Feeding the model with the trained_images and trained_labels\n",
    "# 2) The model learns association between the images and labels\n",
    "# 3) Ask the model to make predictions about a test set. Verify the predictions match the labls from the test_labels array          \n",
    "model.fit(train_images, train_labels, # Training images and labels\n",
    "          validation_data=(test_images, test_labels), # Evaluate the loss and any model metrics at the end of each epoch\n",
    "          batch_size=20, # Too large a mini-batch size usually leads to a lower accuracy\n",
    "          epochs=1, # Number of iterations, for the sake of the Notebook it's 1, would ideally be 12-18\n",
    "          verbose=1) # Provides a progress bar when training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 166us/step\n",
      "\n",
      "Test accuracy: 0.9829000234603882\n"
     ]
    }
   ],
   "source": [
    "# Compare how the model performs on the test dataset\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=1)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with the model trained, it can make predictions on some images\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# A prediction is an array of 10 numbers\n",
    "# It represents the model's confidence that the image corresponds to each of the 10 numbers (0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.42895908e-08, 2.50308165e-08, 9.45587908e-06, 2.70665112e-07,\n",
       "       6.32045793e-09, 3.71155418e-09, 1.50775933e-10, 9.99989033e-01,\n",
       "       1.00202456e-07, 1.08148708e-06], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test neural network prediction on the first image in test_images\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the index with the highest result\n",
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test and make sure it corresponds to the actual result\n",
    "np.argmax(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
